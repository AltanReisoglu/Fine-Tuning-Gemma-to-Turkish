{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104623,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":72254,"modelId":76277},{"sourceId":104625,"sourceType":"modelInstanceVersion","modelInstanceId":72253,"modelId":76277}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers peft bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:08.360791Z","iopub.execute_input":"2024-12-22T15:54:08.360987Z","iopub.status.idle":"2024-12-22T15:54:28.268943Z","shell.execute_reply.started":"2024-12-22T15:54:08.360967Z","shell.execute_reply":"2024-12-22T15:54:28.267866Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nCollecting transformers\n  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\nCollecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, bitsandbytes, transformers, peft\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed bitsandbytes-0.45.0 huggingface-hub-0.27.0 peft-0.14.0 tokenizers-0.21.0 transformers-4.47.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig\nimport torch\nimport numpy as np\nimport pandas as pd\n\nimport bitsandbytes as bnb\nimport torch.nn as nn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:28.270068Z","iopub.execute_input":"2024-12-22T15:54:28.270448Z","iopub.status.idle":"2024-12-22T15:54:33.918088Z","shell.execute_reply.started":"2024-12-22T15:54:28.270396Z","shell.execute_reply":"2024-12-22T15:54:33.916930Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"bnbConfig = BitsAndBytesConfig(\n    load_in_4bit =True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.919120Z","iopub.execute_input":"2024-12-22T15:54:33.919504Z","iopub.status.idle":"2024-12-22T15:54:33.924512Z","shell.execute_reply.started":"2024-12-22T15:54:33.919482Z","shell.execute_reply":"2024-12-22T15:54:33.923882Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.926165Z","iopub.execute_input":"2024-12-22T15:54:33.926397Z","iopub.status.idle":"2024-12-22T15:54:33.944321Z","shell.execute_reply.started":"2024-12-22T15:54:33.926366Z","shell.execute_reply":"2024-12-22T15:54:33.943395Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#some parameters or things that will be used \nclass Config():\n    model_id = \"/kaggle/input/gemma-2/transformers/gemma-2-2b-it/2\"\n    tensorflow_batch=32\n    token_limit = 256\n    num_data_limit = 1000\n    lora_name = \"instructional\"\n    lora_rank = 16\n    lora_alpha=32\n    lr_value = 1e-4 #best learning_rate\n    train_epoch = 7\n    max_steps = 100\n    hf_data_path = \"merve/turkish_instructions\"#input and output about daily topics\n    weight_decay=0.01,\n    epsilon=1e-6\n    adapter_name=\"instructional\"\n    device_map=\"auto\"\n    epoch=15\n    \n    adam_beta1 = 0.9\n    adam_beta2 = 0.995\n    adam_epsilon = 1e-8\n    max_grad_norm = 1.0\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.945512Z","iopub.execute_input":"2024-12-22T15:54:33.945833Z","iopub.status.idle":"2024-12-22T15:54:33.957574Z","shell.execute_reply.started":"2024-12-22T15:54:33.945803Z","shell.execute_reply":"2024-12-22T15:54:33.956873Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if device.type ==\"cuda\":\n    model = AutoModelForCausalLM.from_pretrained(\n        Config.model_id,\n        quantization_config=bnbConfig,\n        device_map= \"auto\",\n        trust_remote_code=True, \n        )\n    print(\"& cuda\")\nelse:\n    model = AutoModelForCausalLM.from_pretrained(\n        Config.model_id,\n        \n        device_map=\"auto\",\n        trust_remote_code=True,\n        )\n    print(\"not cuda\")\n\ntokenizer = AutoTokenizer.from_pretrained(Config.model_id) \ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.958330Z","iopub.execute_input":"2024-12-22T15:54:33.958616Z","iopub.status.idle":"2024-12-22T15:55:11.277594Z","shell.execute_reply.started":"2024-12-22T15:54:33.958590Z","shell.execute_reply":"2024-12-22T15:55:11.276812Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a3162f5f2bb493b9a8ce0d7d8654145"}},"metadata":{}},{"name":"stdout","text":"& cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\ndef text_generator(prompt):\n    input_text = f\"Gemma !{prompt} \"\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n\n    outputs = model.generate(**input_ids,top_k = 40,top_p=1.0)\n    print(\"model output : \\n\")\n    print(tokenizer.decode(outputs[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:11.281012Z","iopub.execute_input":"2024-12-22T15:55:11.281342Z","iopub.status.idle":"2024-12-22T15:55:11.285856Z","shell.execute_reply.started":"2024-12-22T15:55:11.281309Z","shell.execute_reply":"2024-12-22T15:55:11.285103Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"text_generator(\"Beni seviyor musun? .\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:11.286586Z","iopub.execute_input":"2024-12-22T15:55:11.286910Z","iopub.status.idle":"2024-12-22T15:55:14.750593Z","shell.execute_reply.started":"2024-12-22T15:55:11.286886Z","shell.execute_reply":"2024-12-22T15:55:14.749611Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `40` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n  warnings.warn(\nThe 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n","output_type":"stream"},{"name":"stdout","text":"model output : \n\n<bos>Beni seviyor musun? .\n\nI'm not sure what you mean by \"seviyor musun?\"  Could you\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from datasets import load_dataset\n\n# TÃ¼rkÃ§e bir Ã¶rnek: \"turkic-xwmt,turkish_instructions\" veri kÃ¼mesi\ndataset = load_dataset(Config.hf_data_path)\n\ntrain_data = dataset[\"train\"]\ntrain_df = pd.DataFrame(train_data)\ntrain_df\n\ndef merge_instruct_input(rows):\n    if(rows[\" giriÅŸ\"]!=None):\n        rows[\"talimat\"]=rows[\"talimat\"]+\"\\n\"+rows[\" giriÅŸ\"]\n    return rows\n\nmerged_train=train_df.apply(merge_instruct_input,axis=1)[:500].drop(\" giriÅŸ\",axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:14.752350Z","iopub.execute_input":"2024-12-22T15:55:14.752629Z","iopub.status.idle":"2024-12-22T15:55:23.152992Z","shell.execute_reply.started":"2024-12-22T15:55:14.752606Z","shell.execute_reply":"2024-12-22T15:55:23.152198Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b9f670ba744497bf4aab6510d28b7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"instructions.csv:   0%|          | 0.00/21.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d524ebb4bdc4bbf909ca6bd1cda0e37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51563 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0110ed5c03e7441aaa7d8eb87dc3a1a8"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"merged_train.drop(\"Unnamed: 0\",inplace=True,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.154147Z","iopub.execute_input":"2024-12-22T15:55:23.154811Z","iopub.status.idle":"2024-12-22T15:55:23.159494Z","shell.execute_reply.started":"2024-12-22T15:55:23.154769Z","shell.execute_reply":"2024-12-22T15:55:23.158690Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"merged_train[\"full Context\"]=f\"Gemma ! \\n {merged_train['talimat']} \\n {merged_train[' Ã§Ä±ktÄ±']}\"\nmerged_train[\"label\"]=merged_train[\" Ã§Ä±ktÄ±\"]\nmerged_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.160320Z","iopub.execute_input":"2024-12-22T15:55:23.160532Z","iopub.status.idle":"2024-12-22T15:55:23.187792Z","shell.execute_reply.started":"2024-12-22T15:55:23.160513Z","shell.execute_reply":"2024-12-22T15:55:23.186912Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                               talimat  \\\n0     AÅŸaÄŸÄ±daki baÄŸlamda orijinal bir ÅŸey sÃ¶yleyin:...   \n1     AÅŸaÄŸÄ±daki makale iÃ§in bir baÅŸlÄ±k Ã¶nerin: Bu m...   \n2     Åu konuyla ilgili 5 anahtar kelimeden oluÅŸan ...   \n3     Bu cÃ¼mleyi pasiften aktife deÄŸiÅŸtirin: Yeni p...   \n4    AÅŸaÄŸÄ±daki fenomeni tanÄ±mlayan Ã¼Ã§ bilimsel teri...   \n..                                                 ...   \n495   Verilen aralÄ±ktaki tÃ¼m asal sayÄ±larÄ± yazdÄ±ran...   \n496   AÅŸaÄŸÄ±daki Ã¼Ã§ ÅŸehri ziyaret eden bir tatil gÃ¼z...   \n497   Araba kazalarÄ±nÄ±n sayÄ±sÄ±nÄ± azaltmanÄ±n 5 yolun...   \n498   Bir bilgisayar sistemi iÃ§in bileÅŸenlerin bir ...   \n499   AÅŸaÄŸÄ±daki gÄ±da maddesi iÃ§in bir besin deÄŸeri ...   \n\n                                                 Ã§Ä±ktÄ±  \\\n0     Ekibe katkÄ±da bulunmaya baÅŸlamak ve bu alanda...   \n1     \"Dijital Ä°letiÅŸimin GÃ¼cÃ¼: Ä°nternet Ä°ÅŸ OrtamÄ±n...   \n2     1. Karbon emisyonlarÄ± 2. Yenilenebilir enerji...   \n3           Belediye baÅŸkanÄ± yeni politikayÄ± aÃ§Ä±kladÄ±.   \n4     YerÃ§ekimi kuvveti, Newton'un evrensel Ã§ekim y...   \n..                                                 ...   \n495   # Verilen aralÄ±ktaki tÃ¼m asal sayÄ±larÄ± yazdÄ±r...   \n496  1. GÃ¼n: - Hindistan'Ä±n Delhi kentine varÄ±ÅŸ ve ...   \n497  1. Daha iyi aydÄ±nlatma veya daha iyi tabelalar...   \n498  1. Anakart: Sistemin belleÄŸi, iÅŸlemcileri ve d...   \n499  Beslenme Bilgileri | Porsiyon baÅŸÄ±na miktar --...   \n\n                                          full Context  \\\n0    Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n1    Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n2    Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n3    Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n4    Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n..                                                 ...   \n495  Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n496  Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n497  Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n498  Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n499  Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...   \n\n                                                 label  \n0     Ekibe katkÄ±da bulunmaya baÅŸlamak ve bu alanda...  \n1     \"Dijital Ä°letiÅŸimin GÃ¼cÃ¼: Ä°nternet Ä°ÅŸ OrtamÄ±n...  \n2     1. Karbon emisyonlarÄ± 2. Yenilenebilir enerji...  \n3           Belediye baÅŸkanÄ± yeni politikayÄ± aÃ§Ä±kladÄ±.  \n4     YerÃ§ekimi kuvveti, Newton'un evrensel Ã§ekim y...  \n..                                                 ...  \n495   # Verilen aralÄ±ktaki tÃ¼m asal sayÄ±larÄ± yazdÄ±r...  \n496  1. GÃ¼n: - Hindistan'Ä±n Delhi kentine varÄ±ÅŸ ve ...  \n497  1. Daha iyi aydÄ±nlatma veya daha iyi tabelalar...  \n498  1. Anakart: Sistemin belleÄŸi, iÅŸlemcileri ve d...  \n499  Beslenme Bilgileri | Porsiyon baÅŸÄ±na miktar --...  \n\n[500 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>talimat</th>\n      <th>Ã§Ä±ktÄ±</th>\n      <th>full Context</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AÅŸaÄŸÄ±daki baÄŸlamda orijinal bir ÅŸey sÃ¶yleyin:...</td>\n      <td>Ekibe katkÄ±da bulunmaya baÅŸlamak ve bu alanda...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>Ekibe katkÄ±da bulunmaya baÅŸlamak ve bu alanda...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AÅŸaÄŸÄ±daki makale iÃ§in bir baÅŸlÄ±k Ã¶nerin: Bu m...</td>\n      <td>\"Dijital Ä°letiÅŸimin GÃ¼cÃ¼: Ä°nternet Ä°ÅŸ OrtamÄ±n...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>\"Dijital Ä°letiÅŸimin GÃ¼cÃ¼: Ä°nternet Ä°ÅŸ OrtamÄ±n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Åu konuyla ilgili 5 anahtar kelimeden oluÅŸan ...</td>\n      <td>1. Karbon emisyonlarÄ± 2. Yenilenebilir enerji...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>1. Karbon emisyonlarÄ± 2. Yenilenebilir enerji...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bu cÃ¼mleyi pasiften aktife deÄŸiÅŸtirin: Yeni p...</td>\n      <td>Belediye baÅŸkanÄ± yeni politikayÄ± aÃ§Ä±kladÄ±.</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>Belediye baÅŸkanÄ± yeni politikayÄ± aÃ§Ä±kladÄ±.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AÅŸaÄŸÄ±daki fenomeni tanÄ±mlayan Ã¼Ã§ bilimsel teri...</td>\n      <td>YerÃ§ekimi kuvveti, Newton'un evrensel Ã§ekim y...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>YerÃ§ekimi kuvveti, Newton'un evrensel Ã§ekim y...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>Verilen aralÄ±ktaki tÃ¼m asal sayÄ±larÄ± yazdÄ±ran...</td>\n      <td># Verilen aralÄ±ktaki tÃ¼m asal sayÄ±larÄ± yazdÄ±r...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td># Verilen aralÄ±ktaki tÃ¼m asal sayÄ±larÄ± yazdÄ±r...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>AÅŸaÄŸÄ±daki Ã¼Ã§ ÅŸehri ziyaret eden bir tatil gÃ¼z...</td>\n      <td>1. GÃ¼n: - Hindistan'Ä±n Delhi kentine varÄ±ÅŸ ve ...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>1. GÃ¼n: - Hindistan'Ä±n Delhi kentine varÄ±ÅŸ ve ...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>Araba kazalarÄ±nÄ±n sayÄ±sÄ±nÄ± azaltmanÄ±n 5 yolun...</td>\n      <td>1. Daha iyi aydÄ±nlatma veya daha iyi tabelalar...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>1. Daha iyi aydÄ±nlatma veya daha iyi tabelalar...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Bir bilgisayar sistemi iÃ§in bileÅŸenlerin bir ...</td>\n      <td>1. Anakart: Sistemin belleÄŸi, iÅŸlemcileri ve d...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>1. Anakart: Sistemin belleÄŸi, iÅŸlemcileri ve d...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>AÅŸaÄŸÄ±daki gÄ±da maddesi iÃ§in bir besin deÄŸeri ...</td>\n      <td>Beslenme Bilgileri | Porsiyon baÅŸÄ±na miktar --...</td>\n      <td>Gemma ! \\n 0       AÅŸaÄŸÄ±daki baÄŸlamda orijinal...</td>\n      <td>Beslenme Bilgileri | Porsiyon baÅŸÄ±na miktar --...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.188748Z","iopub.execute_input":"2024-12-22T15:55:23.188982Z","iopub.status.idle":"2024-12-22T15:55:23.203027Z","shell.execute_reply.started":"2024-12-22T15:55:23.188961Z","shell.execute_reply":"2024-12-22T15:55:23.202263Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train,valid=train_test_split(merged_train,test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.204036Z","iopub.execute_input":"2024-12-22T15:55:23.204375Z","iopub.status.idle":"2024-12-22T15:55:23.210050Z","shell.execute_reply.started":"2024-12-22T15:55:23.204330Z","shell.execute_reply":"2024-12-22T15:55:23.209210Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from datasets import load_dataset,DatasetDict,Dataset\ntrain_dataset = Dataset.from_pandas(train)\nvalid_dataset = Dataset.from_pandas(valid)\n\n# DatasetDict oluÅŸturma\ndatasetDict = DatasetDict({\n    \"train\": train_dataset,\n    \"valid\": valid_dataset\n})\n\ndatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.210848Z","iopub.execute_input":"2024-12-22T15:55:23.211167Z","iopub.status.idle":"2024-12-22T15:55:23.244906Z","shell.execute_reply.started":"2024-12-22T15:55:23.211142Z","shell.execute_reply":"2024-12-22T15:55:23.244146Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['talimat', ' Ã§Ä±ktÄ±', 'full Context', 'label', '__index_level_0__'],\n        num_rows: 400\n    })\n    valid: Dataset({\n        features: ['talimat', ' Ã§Ä±ktÄ±', 'full Context', 'label', '__index_level_0__'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"DatasetDict[\"__index_level_0__\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:25.843821Z","iopub.execute_input":"2024-12-22T15:56:25.844141Z","iopub.status.idle":"2024-12-22T15:56:25.866944Z","shell.execute_reply.started":"2024-12-22T15:56:25.844114Z","shell.execute_reply":"2024-12-22T15:56:25.865748Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-015794c9e311>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"__index_level_0__\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: There are no type variables left in datasets.dataset_dict.DatasetDict['__index_level_0__']"],"ename":"TypeError","evalue":"There are no type variables left in datasets.dataset_dict.DatasetDict['__index_level_0__']","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"def tokenize_function(examples):\n    \"\"\"\n    Tokenizes text input for model training.\n\n    Args:\n        examples (Dict): A dictionary containing text inputs.\n\n    Returns:\n        Dict: Tokenized text input with truncation applied.\n    \"\"\"\n    return tokenizer(examples[\"full Context\"], max_length = Config.token_limit, truncation = True,padding=True).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:33.795298Z","iopub.execute_input":"2024-12-22T15:56:33.795628Z","iopub.status.idle":"2024-12-22T15:56:33.800249Z","shell.execute_reply.started":"2024-12-22T15:56:33.795590Z","shell.execute_reply":"2024-12-22T15:56:33.799177Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"datasetDict = datasetDict.map(tokenize_function, batched=True) # generate token value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:35.564607Z","iopub.execute_input":"2024-12-22T15:56:35.564960Z","iopub.status.idle":"2024-12-22T15:56:36.725747Z","shell.execute_reply.started":"2024-12-22T15:56:35.564931Z","shell.execute_reply":"2024-12-22T15:56:36.724751Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db03237b19634ed6a3c817a5f9b13f7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d77da5d1fed4811a44f7d2cdc8ad822"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"datasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:39.650566Z","iopub.execute_input":"2024-12-22T15:56:39.650945Z","iopub.status.idle":"2024-12-22T15:56:39.656458Z","shell.execute_reply.started":"2024-12-22T15:56:39.650914Z","shell.execute_reply":"2024-12-22T15:56:39.655638Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['talimat', ' Ã§Ä±ktÄ±', 'full Context', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 400\n    })\n    valid: Dataset({\n        features: ['talimat', ' Ã§Ä±ktÄ±', 'full Context', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"\"\"\"from typing import Dict\ntext=[]\n\n\n# Iterate over the rows in the filtered DataFrame\nfor i, row in merged_train.iterrows():\n    prompt = row['talimat']  # Question\n    output = row[' Ã§Ä±ktÄ±']  # Answer\n\n    # Construct the conversation\n    conversation = (\n        f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n        f\"<start_of_turn>model\\n{output}<end_of_turn>\"\n    )\n\n    # Tokenize and check the length\n    tokenized=tokenizer(conversation)\n    \n    # Skip data if the token length is longer than our limit\n    if len(tokenized[\"input_ids\"]) < Config.token_limit:\n        text.append(tokenized)\n        if len(text) >= Config.num_data_limit:\n            break\n\nprint(f\"Number of training samples: {len(text)}\")\nprint(\"\\nSample conversation:\")\nprint(text)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.856148Z","iopub.status.idle":"2024-12-22T15:52:55.856541Z","shell.execute_reply":"2024-12-22T15:52:55.856357Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Available modules in the Gemma model:\")\nfor name, module in model.named_modules():\n    print(name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.857382Z","iopub.status.idle":"2024-12-22T15:52:55.857712Z","shell.execute_reply":"2024-12-22T15:52:55.857546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Adapter Tuning","metadata":{}},{"cell_type":"markdown","source":"### i prefer adapter tuning since it is fast and soft.After Ä± applied adapter tuning.i apply lora fine tune","metadata":{}},{"cell_type":"code","source":"#freezing the original weight of model\nfor param in model.parameters():\n  param.requires_grad = False  # freeze the model - train adapters later\n  if param.ndim == 1:\n    # cast the small parameters (e.g. layernorm) to fp32 for stability\n    param.data = param.data.to(torch.float32)\n\nmodel.gradient_checkpointing_enable()  # reduce number of stored activations\nmodel.enable_input_require_grads()\n\nclass CastOutputToFloat(nn.Sequential):\n  def forward(self, x): return super().forward(x).to(torch.float32)\nmodel.lm_head = CastOutputToFloat(model.lm_head)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.858352Z","iopub.status.idle":"2024-12-22T15:52:55.858637Z","shell.execute_reply":"2024-12-22T15:52:55.858506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, PeftModel\nlora_config = LoraConfig(\n    r = 16, # Rank\n    lora_alpha = 32, # Adjusting Coefficient\n    \n    target_modules=[\n        \"q_proj\",\"v_proj\",\n    ],\n    bias = \"none\",\n    task_type = \"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:48.901237Z","iopub.execute_input":"2024-12-22T15:56:48.901582Z","iopub.status.idle":"2024-12-22T15:56:49.082148Z","shell.execute_reply.started":"2024-12-22T15:56:48.901556Z","shell.execute_reply":"2024-12-22T15:56:49.081155Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n\nprint_trainable_parameters(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:52.099619Z","iopub.execute_input":"2024-12-22T15:56:52.099977Z","iopub.status.idle":"2024-12-22T15:56:52.108952Z","shell.execute_reply.started":"2024-12-22T15:56:52.099949Z","shell.execute_reply":"2024-12-22T15:56:52.108013Z"}},"outputs":[{"name":"stdout","text":"trainable params: 3194880 || all params: 1605398784 || trainable%: 0.19900849756716896\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model.to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.862061Z","iopub.status.idle":"2024-12-22T15:52:55.862424Z","shell.execute_reply":"2024-12-22T15:52:55.862249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:55.454889Z","iopub.execute_input":"2024-12-22T15:56:55.455205Z","iopub.status.idle":"2024-12-22T15:56:55.459102Z","shell.execute_reply.started":"2024-12-22T15:56:55.455183Z","shell.execute_reply":"2024-12-22T15:56:55.458197Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=1e-4,\n    per_device_train_batch_size=16,  # GPU iÃ§in artÄ±rabilirsiniz\n    per_device_eval_batch_size=16,  # GPU iÃ§in artÄ±rabilirsiniz\n    num_train_epochs=3,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    fp16=True,  # YarÄ± hassasiyet (GPU iÃ§in)\n    dataloader_num_workers=4,  # Daha hÄ±zlÄ± veri yÃ¼kleme\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=datasetDict[\"train\"],\n    eval_dataset=datasetDict[\"valid\"],\n    tokenizer=tokenizer,\n)\n\nhistory=trainer.train()\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:08.901313Z","iopub.execute_input":"2024-12-22T15:57:08.901630Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-27-df0b3cd96e49>:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/lora_model_altan_altaniye.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}