{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104623,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":72254,"modelId":76277},{"sourceId":104625,"sourceType":"modelInstanceVersion","modelInstanceId":72253,"modelId":76277}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers peft bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:08.360791Z","iopub.execute_input":"2024-12-22T15:54:08.360987Z","iopub.status.idle":"2024-12-22T15:54:28.268943Z","shell.execute_reply.started":"2024-12-22T15:54:08.360967Z","shell.execute_reply":"2024-12-22T15:54:28.267866Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nCollecting transformers\n  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\nCollecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, bitsandbytes, transformers, peft\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed bitsandbytes-0.45.0 huggingface-hub-0.27.0 peft-0.14.0 tokenizers-0.21.0 transformers-4.47.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig\nimport torch\nimport numpy as np\nimport pandas as pd\n\nimport bitsandbytes as bnb\nimport torch.nn as nn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:28.270068Z","iopub.execute_input":"2024-12-22T15:54:28.270448Z","iopub.status.idle":"2024-12-22T15:54:33.918088Z","shell.execute_reply.started":"2024-12-22T15:54:28.270396Z","shell.execute_reply":"2024-12-22T15:54:33.916930Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"bnbConfig = BitsAndBytesConfig(\n    load_in_4bit =True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.919120Z","iopub.execute_input":"2024-12-22T15:54:33.919504Z","iopub.status.idle":"2024-12-22T15:54:33.924512Z","shell.execute_reply.started":"2024-12-22T15:54:33.919482Z","shell.execute_reply":"2024-12-22T15:54:33.923882Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.926165Z","iopub.execute_input":"2024-12-22T15:54:33.926397Z","iopub.status.idle":"2024-12-22T15:54:33.944321Z","shell.execute_reply.started":"2024-12-22T15:54:33.926366Z","shell.execute_reply":"2024-12-22T15:54:33.943395Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#some parameters or things that will be used \nclass Config():\n    model_id = \"/kaggle/input/gemma-2/transformers/gemma-2-2b-it/2\"\n    tensorflow_batch=32\n    token_limit = 256\n    num_data_limit = 1000\n    lora_name = \"instructional\"\n    lora_rank = 16\n    lora_alpha=32\n    lr_value = 1e-4 #best learning_rate\n    train_epoch = 7\n    max_steps = 100\n    hf_data_path = \"merve/turkish_instructions\"#input and output about daily topics\n    weight_decay=0.01,\n    epsilon=1e-6\n    adapter_name=\"instructional\"\n    device_map=\"auto\"\n    epoch=15\n    \n    adam_beta1 = 0.9\n    adam_beta2 = 0.995\n    adam_epsilon = 1e-8\n    max_grad_norm = 1.0\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.945512Z","iopub.execute_input":"2024-12-22T15:54:33.945833Z","iopub.status.idle":"2024-12-22T15:54:33.957574Z","shell.execute_reply.started":"2024-12-22T15:54:33.945803Z","shell.execute_reply":"2024-12-22T15:54:33.956873Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if device.type ==\"cuda\":\n    model = AutoModelForCausalLM.from_pretrained(\n        Config.model_id,\n        quantization_config=bnbConfig,\n        device_map= \"auto\",\n        trust_remote_code=True, \n        )\n    print(\"& cuda\")\nelse:\n    model = AutoModelForCausalLM.from_pretrained(\n        Config.model_id,\n        \n        device_map=\"auto\",\n        trust_remote_code=True,\n        )\n    print(\"not cuda\")\n\ntokenizer = AutoTokenizer.from_pretrained(Config.model_id) \ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:54:33.958330Z","iopub.execute_input":"2024-12-22T15:54:33.958616Z","iopub.status.idle":"2024-12-22T15:55:11.277594Z","shell.execute_reply.started":"2024-12-22T15:54:33.958590Z","shell.execute_reply":"2024-12-22T15:55:11.276812Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a3162f5f2bb493b9a8ce0d7d8654145"}},"metadata":{}},{"name":"stdout","text":"& cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\ndef text_generator(prompt):\n    input_text = f\"Gemma !{prompt} \"\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n\n    outputs = model.generate(**input_ids,top_k = 40,top_p=1.0)\n    print(\"model output : \\n\")\n    print(tokenizer.decode(outputs[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:11.281012Z","iopub.execute_input":"2024-12-22T15:55:11.281342Z","iopub.status.idle":"2024-12-22T15:55:11.285856Z","shell.execute_reply.started":"2024-12-22T15:55:11.281309Z","shell.execute_reply":"2024-12-22T15:55:11.285103Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"text_generator(\"Beni seviyor musun? .\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:11.286586Z","iopub.execute_input":"2024-12-22T15:55:11.286910Z","iopub.status.idle":"2024-12-22T15:55:14.750593Z","shell.execute_reply.started":"2024-12-22T15:55:11.286886Z","shell.execute_reply":"2024-12-22T15:55:14.749611Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `40` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n  warnings.warn(\nThe 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n","output_type":"stream"},{"name":"stdout","text":"model output : \n\n<bos>Beni seviyor musun? .\n\nI'm not sure what you mean by \"seviyor musun?\"  Could you\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Türkçe bir örnek: \"turkic-xwmt,turkish_instructions\" veri kümesi\ndataset = load_dataset(Config.hf_data_path)\n\ntrain_data = dataset[\"train\"]\ntrain_df = pd.DataFrame(train_data)\ntrain_df\n\ndef merge_instruct_input(rows):\n    if(rows[\" giriş\"]!=None):\n        rows[\"talimat\"]=rows[\"talimat\"]+\"\\n\"+rows[\" giriş\"]\n    return rows\n\nmerged_train=train_df.apply(merge_instruct_input,axis=1)[:500].drop(\" giriş\",axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:14.752350Z","iopub.execute_input":"2024-12-22T15:55:14.752629Z","iopub.status.idle":"2024-12-22T15:55:23.152992Z","shell.execute_reply.started":"2024-12-22T15:55:14.752606Z","shell.execute_reply":"2024-12-22T15:55:23.152198Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b9f670ba744497bf4aab6510d28b7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"instructions.csv:   0%|          | 0.00/21.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d524ebb4bdc4bbf909ca6bd1cda0e37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51563 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0110ed5c03e7441aaa7d8eb87dc3a1a8"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"merged_train.drop(\"Unnamed: 0\",inplace=True,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.154147Z","iopub.execute_input":"2024-12-22T15:55:23.154811Z","iopub.status.idle":"2024-12-22T15:55:23.159494Z","shell.execute_reply.started":"2024-12-22T15:55:23.154769Z","shell.execute_reply":"2024-12-22T15:55:23.158690Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"merged_train[\"full Context\"]=f\"Gemma ! \\n {merged_train['talimat']} \\n {merged_train[' çıktı']}\"\nmerged_train[\"label\"]=merged_train[\" çıktı\"]\nmerged_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.160320Z","iopub.execute_input":"2024-12-22T15:55:23.160532Z","iopub.status.idle":"2024-12-22T15:55:23.187792Z","shell.execute_reply.started":"2024-12-22T15:55:23.160513Z","shell.execute_reply":"2024-12-22T15:55:23.186912Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                               talimat  \\\n0     Aşağıdaki bağlamda orijinal bir şey söyleyin:...   \n1     Aşağıdaki makale için bir başlık önerin: Bu m...   \n2     Şu konuyla ilgili 5 anahtar kelimeden oluşan ...   \n3     Bu cümleyi pasiften aktife değiştirin: Yeni p...   \n4    Aşağıdaki fenomeni tanımlayan üç bilimsel teri...   \n..                                                 ...   \n495   Verilen aralıktaki tüm asal sayıları yazdıran...   \n496   Aşağıdaki üç şehri ziyaret eden bir tatil güz...   \n497   Araba kazalarının sayısını azaltmanın 5 yolun...   \n498   Bir bilgisayar sistemi için bileşenlerin bir ...   \n499   Aşağıdaki gıda maddesi için bir besin değeri ...   \n\n                                                 çıktı  \\\n0     Ekibe katkıda bulunmaya başlamak ve bu alanda...   \n1     \"Dijital İletişimin Gücü: İnternet İş Ortamın...   \n2     1. Karbon emisyonları 2. Yenilenebilir enerji...   \n3           Belediye başkanı yeni politikayı açıkladı.   \n4     Yerçekimi kuvveti, Newton'un evrensel çekim y...   \n..                                                 ...   \n495   # Verilen aralıktaki tüm asal sayıları yazdır...   \n496  1. Gün: - Hindistan'ın Delhi kentine varış ve ...   \n497  1. Daha iyi aydınlatma veya daha iyi tabelalar...   \n498  1. Anakart: Sistemin belleği, işlemcileri ve d...   \n499  Beslenme Bilgileri | Porsiyon başına miktar --...   \n\n                                          full Context  \\\n0    Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n1    Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n2    Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n3    Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n4    Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n..                                                 ...   \n495  Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n496  Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n497  Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n498  Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n499  Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...   \n\n                                                 label  \n0     Ekibe katkıda bulunmaya başlamak ve bu alanda...  \n1     \"Dijital İletişimin Gücü: İnternet İş Ortamın...  \n2     1. Karbon emisyonları 2. Yenilenebilir enerji...  \n3           Belediye başkanı yeni politikayı açıkladı.  \n4     Yerçekimi kuvveti, Newton'un evrensel çekim y...  \n..                                                 ...  \n495   # Verilen aralıktaki tüm asal sayıları yazdır...  \n496  1. Gün: - Hindistan'ın Delhi kentine varış ve ...  \n497  1. Daha iyi aydınlatma veya daha iyi tabelalar...  \n498  1. Anakart: Sistemin belleği, işlemcileri ve d...  \n499  Beslenme Bilgileri | Porsiyon başına miktar --...  \n\n[500 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>talimat</th>\n      <th>çıktı</th>\n      <th>full Context</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aşağıdaki bağlamda orijinal bir şey söyleyin:...</td>\n      <td>Ekibe katkıda bulunmaya başlamak ve bu alanda...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>Ekibe katkıda bulunmaya başlamak ve bu alanda...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aşağıdaki makale için bir başlık önerin: Bu m...</td>\n      <td>\"Dijital İletişimin Gücü: İnternet İş Ortamın...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>\"Dijital İletişimin Gücü: İnternet İş Ortamın...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Şu konuyla ilgili 5 anahtar kelimeden oluşan ...</td>\n      <td>1. Karbon emisyonları 2. Yenilenebilir enerji...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>1. Karbon emisyonları 2. Yenilenebilir enerji...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bu cümleyi pasiften aktife değiştirin: Yeni p...</td>\n      <td>Belediye başkanı yeni politikayı açıkladı.</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>Belediye başkanı yeni politikayı açıkladı.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Aşağıdaki fenomeni tanımlayan üç bilimsel teri...</td>\n      <td>Yerçekimi kuvveti, Newton'un evrensel çekim y...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>Yerçekimi kuvveti, Newton'un evrensel çekim y...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>Verilen aralıktaki tüm asal sayıları yazdıran...</td>\n      <td># Verilen aralıktaki tüm asal sayıları yazdır...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td># Verilen aralıktaki tüm asal sayıları yazdır...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>Aşağıdaki üç şehri ziyaret eden bir tatil güz...</td>\n      <td>1. Gün: - Hindistan'ın Delhi kentine varış ve ...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>1. Gün: - Hindistan'ın Delhi kentine varış ve ...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>Araba kazalarının sayısını azaltmanın 5 yolun...</td>\n      <td>1. Daha iyi aydınlatma veya daha iyi tabelalar...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>1. Daha iyi aydınlatma veya daha iyi tabelalar...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Bir bilgisayar sistemi için bileşenlerin bir ...</td>\n      <td>1. Anakart: Sistemin belleği, işlemcileri ve d...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>1. Anakart: Sistemin belleği, işlemcileri ve d...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Aşağıdaki gıda maddesi için bir besin değeri ...</td>\n      <td>Beslenme Bilgileri | Porsiyon başına miktar --...</td>\n      <td>Gemma ! \\n 0       Aşağıdaki bağlamda orijinal...</td>\n      <td>Beslenme Bilgileri | Porsiyon başına miktar --...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.188748Z","iopub.execute_input":"2024-12-22T15:55:23.188982Z","iopub.status.idle":"2024-12-22T15:55:23.203027Z","shell.execute_reply.started":"2024-12-22T15:55:23.188961Z","shell.execute_reply":"2024-12-22T15:55:23.202263Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train,valid=train_test_split(merged_train,test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.204036Z","iopub.execute_input":"2024-12-22T15:55:23.204375Z","iopub.status.idle":"2024-12-22T15:55:23.210050Z","shell.execute_reply.started":"2024-12-22T15:55:23.204330Z","shell.execute_reply":"2024-12-22T15:55:23.209210Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from datasets import load_dataset,DatasetDict,Dataset\ntrain_dataset = Dataset.from_pandas(train)\nvalid_dataset = Dataset.from_pandas(valid)\n\n# DatasetDict oluşturma\ndatasetDict = DatasetDict({\n    \"train\": train_dataset,\n    \"valid\": valid_dataset\n})\n\ndatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:23.210848Z","iopub.execute_input":"2024-12-22T15:55:23.211167Z","iopub.status.idle":"2024-12-22T15:55:23.244906Z","shell.execute_reply.started":"2024-12-22T15:55:23.211142Z","shell.execute_reply":"2024-12-22T15:55:23.244146Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['talimat', ' çıktı', 'full Context', 'label', '__index_level_0__'],\n        num_rows: 400\n    })\n    valid: Dataset({\n        features: ['talimat', ' çıktı', 'full Context', 'label', '__index_level_0__'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"DatasetDict[\"__index_level_0__\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:25.843821Z","iopub.execute_input":"2024-12-22T15:56:25.844141Z","iopub.status.idle":"2024-12-22T15:56:25.866944Z","shell.execute_reply.started":"2024-12-22T15:56:25.844114Z","shell.execute_reply":"2024-12-22T15:56:25.865748Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-015794c9e311>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"__index_level_0__\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: There are no type variables left in datasets.dataset_dict.DatasetDict['__index_level_0__']"],"ename":"TypeError","evalue":"There are no type variables left in datasets.dataset_dict.DatasetDict['__index_level_0__']","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"def tokenize_function(examples):\n    \"\"\"\n    Tokenizes text input for model training.\n\n    Args:\n        examples (Dict): A dictionary containing text inputs.\n\n    Returns:\n        Dict: Tokenized text input with truncation applied.\n    \"\"\"\n    return tokenizer(examples[\"full Context\"], max_length = Config.token_limit, truncation = True,padding=True).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:33.795298Z","iopub.execute_input":"2024-12-22T15:56:33.795628Z","iopub.status.idle":"2024-12-22T15:56:33.800249Z","shell.execute_reply.started":"2024-12-22T15:56:33.795590Z","shell.execute_reply":"2024-12-22T15:56:33.799177Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"datasetDict = datasetDict.map(tokenize_function, batched=True) # generate token value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:35.564607Z","iopub.execute_input":"2024-12-22T15:56:35.564960Z","iopub.status.idle":"2024-12-22T15:56:36.725747Z","shell.execute_reply.started":"2024-12-22T15:56:35.564931Z","shell.execute_reply":"2024-12-22T15:56:36.724751Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db03237b19634ed6a3c817a5f9b13f7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d77da5d1fed4811a44f7d2cdc8ad822"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"datasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:39.650566Z","iopub.execute_input":"2024-12-22T15:56:39.650945Z","iopub.status.idle":"2024-12-22T15:56:39.656458Z","shell.execute_reply.started":"2024-12-22T15:56:39.650914Z","shell.execute_reply":"2024-12-22T15:56:39.655638Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['talimat', ' çıktı', 'full Context', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 400\n    })\n    valid: Dataset({\n        features: ['talimat', ' çıktı', 'full Context', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"\"\"\"from typing import Dict\ntext=[]\n\n\n# Iterate over the rows in the filtered DataFrame\nfor i, row in merged_train.iterrows():\n    prompt = row['talimat']  # Question\n    output = row[' çıktı']  # Answer\n\n    # Construct the conversation\n    conversation = (\n        f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n        f\"<start_of_turn>model\\n{output}<end_of_turn>\"\n    )\n\n    # Tokenize and check the length\n    tokenized=tokenizer(conversation)\n    \n    # Skip data if the token length is longer than our limit\n    if len(tokenized[\"input_ids\"]) < Config.token_limit:\n        text.append(tokenized)\n        if len(text) >= Config.num_data_limit:\n            break\n\nprint(f\"Number of training samples: {len(text)}\")\nprint(\"\\nSample conversation:\")\nprint(text)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.856148Z","iopub.status.idle":"2024-12-22T15:52:55.856541Z","shell.execute_reply":"2024-12-22T15:52:55.856357Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Available modules in the Gemma model:\")\nfor name, module in model.named_modules():\n    print(name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.857382Z","iopub.status.idle":"2024-12-22T15:52:55.857712Z","shell.execute_reply":"2024-12-22T15:52:55.857546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Adapter Tuning","metadata":{}},{"cell_type":"markdown","source":"### i prefer adapter tuning since it is fast and soft.After ı applied adapter tuning.i apply lora fine tune","metadata":{}},{"cell_type":"code","source":"#freezing the original weight of model\nfor param in model.parameters():\n  param.requires_grad = False  # freeze the model - train adapters later\n  if param.ndim == 1:\n    # cast the small parameters (e.g. layernorm) to fp32 for stability\n    param.data = param.data.to(torch.float32)\n\nmodel.gradient_checkpointing_enable()  # reduce number of stored activations\nmodel.enable_input_require_grads()\n\nclass CastOutputToFloat(nn.Sequential):\n  def forward(self, x): return super().forward(x).to(torch.float32)\nmodel.lm_head = CastOutputToFloat(model.lm_head)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.858352Z","iopub.status.idle":"2024-12-22T15:52:55.858637Z","shell.execute_reply":"2024-12-22T15:52:55.858506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, PeftModel\nlora_config = LoraConfig(\n    r = 16, # Rank\n    lora_alpha = 32, # Adjusting Coefficient\n    \n    target_modules=[\n        \"q_proj\",\"v_proj\",\n    ],\n    bias = \"none\",\n    task_type = \"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:48.901237Z","iopub.execute_input":"2024-12-22T15:56:48.901582Z","iopub.status.idle":"2024-12-22T15:56:49.082148Z","shell.execute_reply.started":"2024-12-22T15:56:48.901556Z","shell.execute_reply":"2024-12-22T15:56:49.081155Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n\nprint_trainable_parameters(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:52.099619Z","iopub.execute_input":"2024-12-22T15:56:52.099977Z","iopub.status.idle":"2024-12-22T15:56:52.108952Z","shell.execute_reply.started":"2024-12-22T15:56:52.099949Z","shell.execute_reply":"2024-12-22T15:56:52.108013Z"}},"outputs":[{"name":"stdout","text":"trainable params: 3194880 || all params: 1605398784 || trainable%: 0.19900849756716896\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model.to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:55.862061Z","iopub.status.idle":"2024-12-22T15:52:55.862424Z","shell.execute_reply":"2024-12-22T15:52:55.862249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:56:55.454889Z","iopub.execute_input":"2024-12-22T15:56:55.455205Z","iopub.status.idle":"2024-12-22T15:56:55.459102Z","shell.execute_reply.started":"2024-12-22T15:56:55.455183Z","shell.execute_reply":"2024-12-22T15:56:55.458197Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=1e-4,\n    per_device_train_batch_size=16,  # GPU için artırabilirsiniz\n    per_device_eval_batch_size=16,  # GPU için artırabilirsiniz\n    num_train_epochs=3,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    fp16=True,  # Yarı hassasiyet (GPU için)\n    dataloader_num_workers=4,  # Daha hızlı veri yükleme\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=datasetDict[\"train\"],\n    eval_dataset=datasetDict[\"valid\"],\n    tokenizer=tokenizer,\n)\n\nhistory=trainer.train()\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:08.901313Z","iopub.execute_input":"2024-12-22T15:57:08.901630Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-27-df0b3cd96e49>:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/lora_model_altan_altaniye.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}